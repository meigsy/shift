# SHIFT Project Session Summary

**Date**: December 10, 2025  
**Session Focus**: Adaptive Intervention Selector Implementation + Documentation Cleanup

---

## ðŸŽ¯ What We Accomplished

### 1. Implemented Adaptive Intervention Selector with Preference Modeling âœ…

**Core Features Implemented**:
- **Data-driven catalog**: Moved from hard-coded `catalog.py` to BigQuery `intervention_catalog` table
- **Preference-based selection**: Selector now uses `surface_preferences` view to score and filter candidates
- **Suppression logic**: Surfaces with high annoyance rates (`annoyance_rate > 0.7` and `shown_count >= 5`) are automatically suppressed
- **Rate limiting**: Maximum 3 interventions per 30 minutes per user
- **Event type mapping**: Fixed iOS event types (`"tapped"`, `"dismissed"`) â†’ canonical types (`"tap_primary"`, `"dismiss_manual"`) in BigQuery view

**BigQuery Infrastructure Added**:
- `intervention_catalog` table (data-driven catalog)
- `surface_preferences` view (aggregates `app_interactions` over last 30 days)

**Code Changes**:
- Refactored `pipeline/intervention_selector/src/selector.py` to use BigQuery catalog + preferences
- Updated `pipeline/intervention_selector/src/bigquery_client.py` with new helper methods:
  - `get_surface_preferences(user_id)` - Queries preference view
  - `get_catalog_for_stress_level(level)` - Queries catalog table
  - `get_recent_intervention_count(user_id, minutes)` - Rate limiting
- Updated `pipeline/intervention_selector/main.py` to integrate new selector logic and rate limiting
- Updated `pipeline/intervention_selector/http_handler.py` to use BigQuery catalog

### 2. Fixed iOS App Compilation Errors âœ…

- Implemented missing `ApiClient.swift` class (HTTP client with authentication)
- Implemented missing `InterventionService.swift` class (fetches interventions from backend)
- Fixed all compilation errors

### 3. Documentation Consolidation and Cleanup âœ…

**Consolidated Status Files**:
- Merged `IMPLEMENTATION_STATUS.md` and `PROJECT_STATUS_REPORT.md` into single `STATUS.md`
- Removed redundant status files

**Updated Main Documentation**:
- Updated `README.md` to accurately reflect current implementation vs future
- Added "User Preferences and Profile" section documenting:
  - `app_interactions` as canonical preference signal table
  - Chat preference flow (future: via backend endpoint)
  - Preference views (`surface_preferences` current, `user_preferences` future)
  - User profile as conceptual (derived from events/views, not a table)
- Updated event flow diagram to show preference feedback loop
- Updated `pipeline/intervention_selector/README.md` with preference modeling details
- Updated `STATUS.md` with comprehensive implementation status

**Result**: Single source of truth for status, accurate main README, clear documentation structure

### 4. Deployed and Tested âœ…

- Deployed updated Cloud Functions to dev environment
- Loaded initial catalog data (3 stress interventions)
- Verified suppression logic working end-to-end
- Created test scripts for validation (`test_adaptive_loop.sh`, `test_suppression.sh`)

---

## ðŸ“Š Current System State

### âœ… Fully Implemented and Operational

**Core Data Flow** (100% Complete):
1. iOS app â†’ HealthKit data â†’ `watch_events` pipeline â†’ BigQuery âœ…
2. `state_estimator` â†’ Processes watch_events â†’ Calculates state â†’ Publishes to Pub/Sub âœ…
3. `intervention_selector` â†’ Receives Pub/Sub â†’ Queries catalog â†’ Applies preferences â†’ Selects intervention â†’ Creates instance âœ…
4. iOS app â†’ Polls every 60s â†’ Fetches interventions â†’ Displays banner âœ…
5. User interaction â†’ Recorded to `app_interactions` â†’ Feeds into `surface_preferences` â†’ Influences future selections âœ…

**Adaptive Learning** (100% Complete):
- Preference calculation âœ…
- Suppression logic âœ…
- Catalog-based selection âœ…
- Rate limiting âœ…

**BigQuery Tables**:
- `watch_events` (raw HealthKit data)
- `state_estimates` (calculated state scores)
- `intervention_instances` (created interventions)
- `app_interactions` (canonical preference signal events)
- `devices` (device tokens for push notifications)
- `intervention_catalog` (data-driven catalog) âœ… **NEW**

**BigQuery Views**:
- `trace_full_chain` (end-to-end traceability)
- `surface_preferences` (user preference aggregation) âœ… **NEW**
- `v_state_estimator_input_v1` (state estimator input)
- `v_state_estimator_unprocessed_v1` (unprocessed records)

### ðŸš§ Partially Complete

- **Intervention Catalog**: Infrastructure ready, 3 initial interventions loaded. Needs process for updating (manual SQL or future Google Sheet sync)
- **Surface Preferences**: View created and working. Needs more interaction data to build meaningful preferences (works with defaults until data accumulates)

### ðŸ“‹ Not Yet Implemented (Future)

- Withings integration (`withings_events` pipeline)
- Chat integration (`chat_events` pipeline)
- Push notifications (code exists but not fully wired in iOS)
- In-app intervention surfaces (only notification banner exists)
- Multi-metric selection (currently only stress)
- Advanced preference learning algorithms
- A/B testing framework

---

## ðŸ—ï¸ Key Architectural Decisions

### Preference System Design

**Canonical Preference Signals**: `app_interactions` table is the **single source of truth** for all preference signals:
- Currently: iOS app writes interaction events directly (`"shown"`, `"tapped"`, `"dismissed"`)
- Future: Chat will write preference updates via backend endpoint (e.g., `event_type="chat_pref_update"`, `channel="chat"`, with JSON payload)
- **Key principle**: All preference-related signals from both app UI and chat end up in the same fact table, ensuring a unified view

**Preference Views**:
- `surface_preferences` (current): Aggregates `app_interactions` over last 30 days for surface-level delivery preferences
- `user_preferences` (future): Will aggregate preference events for cross-surface preferences (tone, modality, timing)

**User Profile**: Currently **conceptual**â€”no dedicated `user_profile` table. Profile is inferred from:
- Behavioral preferences: Derived from views over event tables (`surface_preferences`, future `user_preferences`)
- Static context: Lives in `devices` table and any future configuration tables
- Future: May introduce small `users`/`user_profile` table for slow-changing attributes (timezone, locale, goals, experiment flags)

### Event Type Mapping

iOS app sends: `"shown"`, `"tapped"`, `"dismissed"`  
Canonical types: `"shown"`, `"tap_primary"`, `"dismiss_manual"`, `"dismiss_timeout"`

Mapping happens in `surface_preferences` BigQuery view SQL:
- `"tapped"` â†’ `"tap_primary"`
- `"dismissed"` â†’ `"dismiss_manual"` (iOS doesn't distinguish manual vs timeout yet)

### Selection Logic

1. Query `intervention_catalog` for enabled interventions matching stress level
2. For each candidate, look up user's `surface_preferences`
3. Calculate `final_score`:
   - If `shown_count >= 5` AND `annoyance_rate > 0.7`: `final_score = -1.0` (suppressed)
   - Otherwise: `final_score = preference_score` (defaults to 0.0 if no preferences)
4. Filter out suppressed candidates (`final_score < 0`)
5. Select candidate with highest `final_score`
6. Check rate limiting (max 3 interventions per 30 minutes per user)

---

## ðŸ“ Important Context for Future Work

### Current Delivery Model

**Phase 1 (Current - Polling-based)**:
- iOS app polls `GET /interventions?user_id=X&status=created` every 60 seconds
- No Apple Developer account required
- Works immediately without APNs setup
- Target latency: 20-30 seconds (currently ~60s due to polling)

**Future (Push-based)**:
- APNs push notifications sent immediately when intervention created
- Code exists but not fully wired in iOS
- Would reduce latency to 20-30 seconds

### Testing Status

**Unit Tests**:
- âœ… State estimator: Repository pattern with mocked tests
- âŒ Intervention selector: No unit tests yet
- âŒ iOS app: No unit tests yet

**Integration Tests**:
- âœ… End-to-end flow tested manually
- âœ… Suppression logic verified
- âœ… Preference calculation verified
- âŒ Automated integration tests not yet implemented

### Known Issues / Technical Debt

1. **Event type distinction**: iOS doesn't distinguish `dismiss_manual` vs `dismiss_timeout` (all map to `dismiss_manual` for now)
2. **No automated tests**: Intervention selector lacks unit/integration tests
3. **Catalog management**: Manual SQL inserts for now (no UI or sync process)
4. **Logging visibility**: Suppression decisions could be more visible in logs
5. **Polling latency**: 60-second polling adds latency (push notifications would improve this)

### Next Priorities

**Immediate (1-2 Weeks)**:
1. Expand intervention catalog (add interventions for recovery/readiness/fatigue metrics)
2. Improve observability (structured logging, monitoring dashboards)
3. Add test coverage (unit tests for intervention selector)
4. Catalog management (document process, consider automation)

**Short-term (1 Month)**:
1. Push notifications (wire up APNs push notification receiving in iOS)
2. Multi-metric selection (extend selector to use recovery/readiness/fatigue, not just stress)
3. In-app surfaces (implement in-app intervention display)
4. Production deployment (deploy to production environment)

**Medium-term (1 Quarter)**:
1. Withings integration (build `withings_events` pipeline)
2. Advanced learning (more sophisticated preference algorithms)
3. A/B testing framework (test intervention variations)
4. Conversational AI (chat-based intervention delivery)

---

## ðŸ“š Documentation Structure

**Main Documentation**:
- `README.md` - Main project overview, architecture, vision, user preferences and profile
- `STATUS.md` - Current implementation status, next steps, known issues

**Pipeline Documentation**:
- `pipeline/watch_events/README.md` - Health data ingestion
- `pipeline/state_estimator/README.md` - State estimation pipeline
- `pipeline/intervention_selector/README.md` - Adaptive intervention selection with preference modeling

**Testing & Validation**:
- `MANUAL_HEALTHKIT_TEST_GUIDE.md` - Manual testing guide
- `pipeline/state_estimator/SQL_VALIDATION_CHECKLIST.md` - SQL validation reference
- `pipeline/state_estimator/VALIDATION_RESULTS.md` - Historical validation results

**Infrastructure**:
- `terraform/projects/dev/README.md` - Terraform infrastructure documentation

**iOS App**:
- `ios_app/README.md` - iOS app architecture and implementation

---

## ðŸ”‘ Key Files to Know

### Intervention Selector Pipeline
- `pipeline/intervention_selector/main.py` - Pub/Sub-triggered Cloud Function
- `pipeline/intervention_selector/http_handler.py` - HTTP-triggered Cloud Function
- `pipeline/intervention_selector/src/selector.py` - Core selection logic (uses catalog + preferences)
- `pipeline/intervention_selector/src/bigquery_client.py` - BigQuery operations (catalog, preferences, rate limiting)
- `pipeline/intervention_selector/src/catalog.py` - âš ï¸ Deprecated (use BigQuery `intervention_catalog` table)

### BigQuery Infrastructure
- `terraform/projects/dev/resources.tf` - Contains `intervention_catalog` table and `surface_preferences` view definitions

### Test Scripts
- `test_adaptive_loop.sh` - Test preference calculation and suppression
- `test_suppression.sh` - Test suppression logic
- `load_intervention_catalog.sh` - Load initial catalog data

---

## ðŸŽ“ Key Learnings

1. **SQL-First Works Well**: Preference aggregation in SQL view is cleaner than Python
2. **Event Type Mapping Critical**: Had to map iOS events to canonical types in view
3. **Suppression Logic Effective**: High annoyance surfaces are automatically suppressed
4. **Repository Pattern Enables Testing**: State estimator tests are clean with mocked repos
5. **Traceability Essential**: `trace_id` makes debugging much easier
6. **Documentation Consolidation Important**: Single source of truth prevents confusion

---

## ðŸš€ Overall Assessment

**Status**: MVP adaptive loop is **complete and operational**. System is learning from user behavior and adapting intervention selection accordingly.

**Progress**: ~90% of MVP complete. Core adaptive loop is operational.

**Next Milestone**: Production-ready adaptive intervention system (2-4 weeks with focused effort on push notifications, test coverage, monitoring, production deployment)

---

## ðŸ“ž Quick Reference

**GCP Project**: `shift-dev-478422` (dev), `shift-prod` (prod)  
**BigQuery Dataset**: `shift_data`  
**Key Tables**: `watch_events`, `state_estimates`, `intervention_instances`, `app_interactions`, `intervention_catalog`  
**Key Views**: `surface_preferences`, `trace_full_chain`, `v_state_estimator_input_v1`  
**Deployment**: `./deploy.sh` (validates Terraform, builds containers, deploys)

---

**Last Updated**: December 10, 2025  
**Session**: Adaptive Selector Implementation + Documentation Cleanup

